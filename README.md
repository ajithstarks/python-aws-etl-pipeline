# Enhanced ETL Workflow with Python, AWS S3, RDS, and Glue

## Project Overview
This project demonstrates an Enhanced ETL pipeline, integrating AWS services (S3, RDS, Glue) with Python for handling CSV, JSON, and XML files.

### Technologies Used
- Python
- AWS S3 (Storage)
- AWS RDS (Relational Database)
- Pandas for data transformation
- SQLAlchemy for database interactions

### Steps to Run the Project:
1. Install the dependencies:
    ```bash
    pip install -r requirements.txt
    ```
2. Set up AWS credentials (Access key, Secret key).
3. Create an S3 bucket and RDS instance.
4. Run the `etl_pipeline.py` script:
    ```bash
    python etl_pipeline.py
    ```

### Project Structure:
